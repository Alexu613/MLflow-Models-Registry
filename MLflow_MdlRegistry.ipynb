{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow: Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Introduction to model registry\n",
    "The Model Registry in MLflow is a centralized system to manage the lifecycle of machine learning models. It provides a way to organize, track, and control models as they progress through different stages of development and deployment. Here's a breakdown of its key features and concepts:\n",
    "\n",
    "Key Features of the MLflow Model Registry:\n",
    "Model Versioning:\n",
    "\n",
    "Every time you register a new model or update an existing one, the Model Registry automatically assigns it a unique version number.\n",
    "This helps you keep track of changes and maintain a history of all model versions.\n",
    "\n",
    "**Model Stages:**\n",
    "\n",
    "Models can be assigned to one of the following stages:\n",
    "- None: Default stage when a model is first registered.\n",
    "- Staging: Indicates the model is being tested or validated.\n",
    "- Production: Indicates the model is ready for deployment.\n",
    "- Archived: Indicates the model is no longer in use but retained for reference.\n",
    "You can transition models between these stages to reflect their lifecycle.\n",
    "\n",
    "**Model Metadata :**\n",
    "\n",
    "- The registry stores metadata about each model, such as:\n",
    "Who created the model. When it was created. Associated tags or descriptions. This metadata helps in auditing and understanding the model's context.\n",
    "\n",
    "- Model Lineage:\n",
    "The registry links models to their training runs in MLflow Tracking.\n",
    "This allows you to trace back to the data, code, and parameters used to train the model.\n",
    "\n",
    "- Access Control:\n",
    "You can set permissions to control who can register, update, or transition models between stages.\n",
    "\n",
    "- Integration with Deployment:\n",
    "The Model Registry integrates with deployment tools, making it easier to serve models directly from the registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries :\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "class AutomaticMLflowLogger:\n",
    "    \"\"\"\n",
    "    AutomaticMLflowLogger class:\n",
    "    Generates a synthetic classification dataset, converts it to DataFrame, splits it into train/test sets,\n",
    "    and logs a LogisticRegression model with MLflow.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_samples:int, n_features:int, n_informative:int, n_redundant:int, random_state:int, n_classes:int) -> None:\n",
    "        \"\"\"\n",
    "        Initializes an instance of AutomaticMLflowLogger.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_samples : int\n",
    "            Total number of samples to generate (e.g., 1000).\n",
    "        n_features : int\n",
    "            Total number of features (e.g., 20).\n",
    "        n_informative : int\n",
    "            Number of informative features (e.g., 10).\n",
    "        n_redundant : int\n",
    "            Number of redundant features (e.g., 5).\n",
    "        random_state : int\n",
    "            Random seed for reproducibility (e.g., 42).\n",
    "        n_classes : int\n",
    "            Number of classes in the target variable (e.g., 3).\n",
    "        \"\"\"\n",
    "        self.n_samples = n_samples\n",
    "        self.n_features = n_features\n",
    "        self.n_informative = n_informative\n",
    "        self.n_redundant = n_redundant\n",
    "        self.random_state = random_state\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Generate classification dataset\n",
    "        self.X, self.y = make_classification(\n",
    "            n_samples=n_samples,\n",
    "            n_features=n_features,\n",
    "            n_informative=n_informative,\n",
    "            n_redundant=n_redundant,\n",
    "            random_state=random_state,\n",
    "            n_classes=n_classes\n",
    "        )\n",
    "\n",
    "        # Print dataset info\n",
    "        print(\"INFORMATION ON THE GENERATED DATASET:\")\n",
    "        print(f\"--------------------------------------\")\n",
    "        print(f\"X dtype: {self.X.dtype}, y dtype: {self.y.dtype}\")\n",
    "        print(f\"Number of samples: {n_samples}, Features: {n_features}, Classes: {n_classes}\")\n",
    "        print(f\"First 5 rows of X:\\n{self.X[:5]}\")\n",
    "        print(f\"First 5 rows of y:\\n{self.y[:5]}\")\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert X and y into a pandas DataFrame.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            DataFrame with feature columns named feature_0, ..., feature_n and target column named 'target'.\n",
    "        \"\"\"\n",
    "        self.df = pd.DataFrame(data=self.X, columns=[f\"feature_{n}\" for n in range(self.X.shape[1])])\n",
    "        self.df[\"target\"] = self.y\n",
    "        return self.df\n",
    "\n",
    "    def split_dataframe(self, test_size:float=0.2, random_state:int=None) -> None:\n",
    "        \"\"\"\n",
    "        Split the dataset into train and test sets using sklearn's train_test_split.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_size : float\n",
    "            Proportion of the dataset to include in the test split (default=0.2)\n",
    "        random_state : int\n",
    "            Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        print(f\"X_train shape: {self.X_train.shape}, y_train shape: {self.y_train.shape}\")\n",
    "        print(f\"X_test shape: {self.X_test.shape}, y_test shape: {self.y_test.shape}\")\n",
    "\n",
    "    def tracking_params_with_mlflow(self, name_experiment: str, penalty=\"l2\", solver=\"lbfgs\", random_state=42, n_jobs=1, run_name=\"run\"):\n",
    "        \"\"\"\n",
    "        Train a LogisticRegression model and log it with MLflow.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        name_experiment : str\n",
    "            Name of the MLflow experiment.\n",
    "        penalty : str\n",
    "            Regularization type (default: 'l2').\n",
    "        solver : str\n",
    "            Solver for LogisticRegression (default: 'lbfgs').\n",
    "        random_state : int\n",
    "            Random state for reproducibility (default: 42).\n",
    "        n_jobs : int\n",
    "            Number of parallel jobs (default: 1).\n",
    "        run_name : str\n",
    "            Name of the MLflow run (default: 'run').\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Set experiment\n",
    "            mlflow.set_experiment(name_experiment)\n",
    "            mlflow.sklearn.autolog()  # Enable automatic logging\n",
    "\n",
    "            # Start run\n",
    "            with mlflow.start_run(run_name=run_name):\n",
    "                model = LogisticRegression(penalty=penalty, solver=solver, random_state=random_state, n_jobs=n_jobs)\n",
    "                model.fit(self.X_train, self.y_train)\n",
    "\n",
    "                # Predictions\n",
    "                y_train_pred = model.predict(self.X_train)\n",
    "                y_test_pred = model.predict(self.X_test)\n",
    "\n",
    "                # Metrics\n",
    "                train_acc = accuracy_score(self.y_train, y_train_pred)\n",
    "                test_acc = accuracy_score(self.y_test, y_test_pred)\n",
    "                print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "                print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in MLflow logging: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/29 19:56:45 INFO mlflow.tracking.fluent: Experiment with name 'Classification_Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFORMATION ON THE GENERATED DATASET:\n",
      "--------------------------------------\n",
      "X dtype: float64, y dtype: int64\n",
      "Number of samples: 1000, Features: 10, Classes: 3\n",
      "First 5 rows of X:\n",
      "[[-2.56891645 -0.25740861 -2.67935708  3.86481793  2.56499796 -0.73755596\n",
      "  -3.33098499 -1.21337007 -1.47310497 -0.84638564]\n",
      " [ 0.62286056  0.53454361  0.01828302 -0.28338169  1.90763743 -0.34130985\n",
      "   1.20623966 -1.09353229 -0.46979071 -0.18802193]\n",
      " [-0.17125115 -0.49627753  1.61334708  2.48806861 -1.67796555  0.30360427\n",
      "  -2.10457904  0.71453069  3.47599878  0.6233862 ]\n",
      " [-0.87142307 -0.3339456   3.36844633  0.97215326 -0.13438845  0.21281985\n",
      "   0.70089905  0.71604575 -1.30090958  3.43983124]\n",
      " [ 2.34640238 -0.69996534 -0.20325055 -0.25674549 -1.97425145  0.61966312\n",
      "  -1.24795009 -1.66211471  3.92145164 -0.75949065]]\n",
      "First 5 rows of y:\n",
      "[1 1 0 1 0]\n",
      "X_train shape: (750, 10), y_train shape: (750,)\n",
      "X_test shape: (250, 10), y_test shape: (250,)\n",
      "Train Accuracy: 0.7013\n",
      "Test Accuracy: 0.7160\n"
     ]
    }
   ],
   "source": [
    "logger = AutomaticMLflowLogger(1000, 10, 5, 2, 42, 3)\n",
    "df = logger.to_dataframe()\n",
    "logger.split_dataframe(test_size=0.25, random_state=42)\n",
    "logger.tracking_params_with_mlflow(name_experiment=\"Classification_Experiment\", run_name=\"Logit_Run_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Importing our own librairy:\n",
    "This code snippet demonstrates the use of a class called AutomaticMLflowLogger from a module named package_ml. Here's a breakdown of what each line does conceptually:\n",
    "\n",
    "- 1. Instantiating the Logger:\n",
    "This creates an instance of the AutomaticMLflowLogger class.\n",
    "The arguments (1000, 10, 5, 2, 42, 3) are likely parameters that configure the logger. For example:\n",
    "1000 might represent the number of data points.\n",
    "10 could be the number of features.\n",
    "5 might indicate the number of classes or categories.\n",
    "2 could be related to the type of model or task.\n",
    "42 is commonly used as a random seed for reproducibility.\n",
    "3 might specify the number of iterations, folds, or another configuration.\n",
    "\n",
    "- 2. Converting to a DataFrame:\n",
    "This method likely generates a dataset (e.g., synthetic or preprocessed data) and converts it into a pandas DataFrame.\n",
    "The resulting df is a structured table that can be used for further analysis or modeling.\n",
    "\n",
    "- 3. Splitting the Data:\n",
    "This splits the DataFrame into training and testing sets.\n",
    "test_size=0.25 means 25% of the data will be used for testing, and the remaining 75% for training.\n",
    "random_state=42 ensures the split is reproducible.\n",
    "\n",
    "- 4. Tracking Parameters with MLflow:\n",
    "This method integrates with MLflow, a tool for tracking machine learning experiments.\n",
    "name_experiment=\"Classification_Experiment\" sets the name of the MLflow experiment.\n",
    "run_name=\"Logit_Run_2\" specifies the name of the current run within the experiment.\n",
    "The method likely logs parameters, metrics, and other details to MLflow for tracking and reproducibility.\n",
    "\n",
    "    **Summary:**\n",
    "    \n",
    "The code initializes a logger, generates a dataset, splits it into training and testing sets, and tracks the experiment's parameters and metadata using MLflow. This workflow is useful for managing machine learning experiments systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/MLflow-Models-Registry/package_ml.py\n"
     ]
    }
   ],
   "source": [
    "import package_ml\n",
    "print(package_ml.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFORMATION ON THE GENERATED DATASET:\n",
      "--------------------------------------\n",
      "X dtype: float64, y dtype: int64\n",
      "Number of samples: 1000, Features: 10, Classes: 3\n",
      "First 5 rows of X:\n",
      "[[-2.56891645 -0.25740861 -2.67935708  3.86481793  2.56499796 -0.73755596\n",
      "  -3.33098499 -1.21337007 -1.47310497 -0.84638564]\n",
      " [ 0.62286056  0.53454361  0.01828302 -0.28338169  1.90763743 -0.34130985\n",
      "   1.20623966 -1.09353229 -0.46979071 -0.18802193]\n",
      " [-0.17125115 -0.49627753  1.61334708  2.48806861 -1.67796555  0.30360427\n",
      "  -2.10457904  0.71453069  3.47599878  0.6233862 ]\n",
      " [-0.87142307 -0.3339456   3.36844633  0.97215326 -0.13438845  0.21281985\n",
      "   0.70089905  0.71604575 -1.30090958  3.43983124]\n",
      " [ 2.34640238 -0.69996534 -0.20325055 -0.25674549 -1.97425145  0.61966312\n",
      "  -1.24795009 -1.66211471  3.92145164 -0.75949065]]\n",
      "First 5 rows of y:\n",
      "[1 1 0 1 0]\n",
      "X_train shape: (750, 10), y_train shape: (750,)\n",
      "X_test shape: (250, 10), y_test shape: (250,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/30 13:03:57 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/30 13:03:57 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/30 13:03:57 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/30 13:03:57 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/30 13:03:57 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/30 13:03:57 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/30 13:04:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7013\n",
      "Test Accuracy: 0.7160\n",
      "adb1cbd06aba4f748d4f224189f5a3b0\n"
     ]
    }
   ],
   "source": [
    "from package_ml import AutomaticMLflowLogger\n",
    "\n",
    "logger = AutomaticMLflowLogger(1000, 10, 5, 2, 42, 3)\n",
    "df = logger.to_dataframe()\n",
    "logger.split_dataframe(test_size=0.25, random_state=42)\n",
    "logger.tracking_params_with_mlflow(name_experiment=\"Classification_Experiment\", run_name=\"Logit_Run_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
