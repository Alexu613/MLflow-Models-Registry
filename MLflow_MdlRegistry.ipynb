{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow : Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Introduction to model registry\n",
    "The Model Registry in MLflow is a centralized system to manage the lifecycle of machine learning models. It provides a way to organize, track, and control models as they progress through different stages of development and deployment. Here's a breakdown of its key features and concepts:\n",
    "\n",
    "Key Features of the MLflow Model Registry:\n",
    "Model Versioning:\n",
    "\n",
    "Every time you register a new model or update an existing one, the Model Registry automatically assigns it a unique version number.\n",
    "This helps you keep track of changes and maintain a history of all model versions.\n",
    "\n",
    "**Model Stages:**\n",
    "\n",
    "Models can be assigned to one of the following stages:\n",
    "- None: Default stage when a model is first registered.\n",
    "- Staging: Indicates the model is being tested or validated.\n",
    "- Production: Indicates the model is ready for deployment.\n",
    "- Archived: Indicates the model is no longer in use but retained for reference.\n",
    "You can transition models between these stages to reflect their lifecycle.\n",
    "\n",
    "**Model Metadata :**\n",
    "\n",
    "- The registry stores metadata about each model, such as:\n",
    "Who created the model. When it was created. Associated tags or descriptions. This metadata helps in auditing and understanding the model's context.\n",
    "\n",
    "- Model Lineage:\n",
    "The registry links models to their training runs in MLflow Tracking.\n",
    "This allows you to trace back to the data, code, and parameters used to train the model.\n",
    "\n",
    "- Access Control:\n",
    "You can set permissions to control who can register, update, or transition models between stages.\n",
    "\n",
    "- Integration with Deployment:\n",
    "The Model Registry integrates with deployment tools, making it easier to serve models directly from the registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries :\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "class AutomaticMLflowLogger:\n",
    "    \"\"\"\n",
    "    AutomaticMLflowLogger class:\n",
    "    Generates a synthetic classification dataset, converts it to DataFrame, splits it into train/test sets,\n",
    "    and logs a LogisticRegression model with MLflow.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_samples:int, n_features:int, n_informative:int, n_redundant:int, random_state:int, n_classes:int) -> None:\n",
    "        \"\"\"\n",
    "        Initializes an instance of AutomaticMLflowLogger.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_samples : int\n",
    "            Total number of samples to generate (e.g., 1000).\n",
    "        n_features : int\n",
    "            Total number of features (e.g., 20).\n",
    "        n_informative : int\n",
    "            Number of informative features (e.g., 10).\n",
    "        n_redundant : int\n",
    "            Number of redundant features (e.g., 5).\n",
    "        random_state : int\n",
    "            Random seed for reproducibility (e.g., 42).\n",
    "        n_classes : int\n",
    "            Number of classes in the target variable (e.g., 3).\n",
    "        \"\"\"\n",
    "        self.n_samples = n_samples\n",
    "        self.n_features = n_features\n",
    "        self.n_informative = n_informative\n",
    "        self.n_redundant = n_redundant\n",
    "        self.random_state = random_state\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Generate classification dataset\n",
    "        self.X, self.y = make_classification(\n",
    "            n_samples=n_samples,\n",
    "            n_features=n_features,\n",
    "            n_informative=n_informative,\n",
    "            n_redundant=n_redundant,\n",
    "            random_state=random_state,\n",
    "            n_classes=n_classes\n",
    "        )\n",
    "\n",
    "        # Print dataset info\n",
    "        print(\"INFORMATION ON THE GENERATED DATASET:\")\n",
    "        print(f\"--------------------------------------\")\n",
    "        print(f\"X dtype: {self.X.dtype}, y dtype: {self.y.dtype}\")\n",
    "        print(f\"Number of samples: {n_samples}, Features: {n_features}, Classes: {n_classes}\")\n",
    "        print(f\"First 5 rows of X:\\n{self.X[:5]}\")\n",
    "        print(f\"First 5 rows of y:\\n{self.y[:5]}\")\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert X and y into a pandas DataFrame.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            DataFrame with feature columns named feature_0, ..., feature_n and target column named 'target'.\n",
    "        \"\"\"\n",
    "        self.df = pd.DataFrame(data=self.X, columns=[f\"feature_{n}\" for n in range(self.X.shape[1])])\n",
    "        self.df[\"target\"] = self.y\n",
    "        return self.df\n",
    "\n",
    "    def split_dataframe(self, test_size:float=0.2, random_state:int=None) -> None:\n",
    "        \"\"\"\n",
    "        Split the dataset into train and test sets using sklearn's train_test_split.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_size : float\n",
    "            Proportion of the dataset to include in the test split (default=0.2)\n",
    "        random_state : int\n",
    "            Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        print(f\"X_train shape: {self.X_train.shape}, y_train shape: {self.y_train.shape}\")\n",
    "        print(f\"X_test shape: {self.X_test.shape}, y_test shape: {self.y_test.shape}\")\n",
    "\n",
    "    def tracking_params_with_mlflow(self, name_experiment: str, penalty=\"l2\", solver=\"lbfgs\", random_state=42, n_jobs=1, run_name=\"run\"):\n",
    "        \"\"\"\n",
    "        Train a LogisticRegression model and log it with MLflow.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        name_experiment : str\n",
    "            Name of the MLflow experiment.\n",
    "        penalty : str\n",
    "            Regularization type (default: 'l2').\n",
    "        solver : str\n",
    "            Solver for LogisticRegression (default: 'lbfgs').\n",
    "        random_state : int\n",
    "            Random state for reproducibility (default: 42).\n",
    "        n_jobs : int\n",
    "            Number of parallel jobs (default: 1).\n",
    "        run_name : str\n",
    "            Name of the MLflow run (default: 'run').\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Set experiment\n",
    "            mlflow.set_experiment(name_experiment)\n",
    "            mlflow.sklearn.autolog()  # Enable automatic logging\n",
    "\n",
    "            # Start run\n",
    "            with mlflow.start_run(run_name=run_name):\n",
    "                model = LogisticRegression(penalty=penalty, solver=solver, random_state=random_state, n_jobs=n_jobs)\n",
    "                model.fit(self.X_train, self.y_train)\n",
    "\n",
    "                # Predictions\n",
    "                y_train_pred = model.predict(self.X_train)\n",
    "                y_test_pred = model.predict(self.X_test)\n",
    "\n",
    "                # Metrics\n",
    "                train_acc = accuracy_score(self.y_train, y_train_pred)\n",
    "                test_acc = accuracy_score(self.y_test, y_test_pred)\n",
    "                print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "                print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in MLflow logging: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/29 19:56:45 INFO mlflow.tracking.fluent: Experiment with name 'Classification_Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFORMATION ON THE GENERATED DATASET:\n",
      "--------------------------------------\n",
      "X dtype: float64, y dtype: int64\n",
      "Number of samples: 1000, Features: 10, Classes: 3\n",
      "First 5 rows of X:\n",
      "[[-2.56891645 -0.25740861 -2.67935708  3.86481793  2.56499796 -0.73755596\n",
      "  -3.33098499 -1.21337007 -1.47310497 -0.84638564]\n",
      " [ 0.62286056  0.53454361  0.01828302 -0.28338169  1.90763743 -0.34130985\n",
      "   1.20623966 -1.09353229 -0.46979071 -0.18802193]\n",
      " [-0.17125115 -0.49627753  1.61334708  2.48806861 -1.67796555  0.30360427\n",
      "  -2.10457904  0.71453069  3.47599878  0.6233862 ]\n",
      " [-0.87142307 -0.3339456   3.36844633  0.97215326 -0.13438845  0.21281985\n",
      "   0.70089905  0.71604575 -1.30090958  3.43983124]\n",
      " [ 2.34640238 -0.69996534 -0.20325055 -0.25674549 -1.97425145  0.61966312\n",
      "  -1.24795009 -1.66211471  3.92145164 -0.75949065]]\n",
      "First 5 rows of y:\n",
      "[1 1 0 1 0]\n",
      "X_train shape: (750, 10), y_train shape: (750,)\n",
      "X_test shape: (250, 10), y_test shape: (250,)\n",
      "Train Accuracy: 0.7013\n",
      "Test Accuracy: 0.7160\n"
     ]
    }
   ],
   "source": [
    "logger = AutomaticMLflowLogger(1000, 10, 5, 2, 42, 3)\n",
    "df = logger.to_dataframe()\n",
    "logger.split_dataframe(test_size=0.25, random_state=42)\n",
    "logger.tracking_params_with_mlflow(name_experiment=\"Classification_Experiment\", run_name=\"Logit_Run_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
